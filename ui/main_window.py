import os
import numpy as np
from pathlib import Path
from PyQt6.QtWidgets import (QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,
                            QPushButton, QLabel, QFileDialog, QFrame, QApplication, QMessageBox, QSplitter)
from PyQt6.QtCore import Qt, QTimer, pyqtSignal, QThread
from PyQt6.QtGui import QFont, QAction

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from .model_history import ModelHistoryWidget
from .model_loader import ModelLoaderDialog
from .tabbed_audio_control import TabbedAudioControl
from .multi_text import MultiTextWidget
from .keyboard_shortcuts import KeyboardShortcutManager
from .sliding_menu import SlidingMenuWidget
from .help_dialog import HelpDialog
from .character_display import CharacterDisplayWidget
from .tts_worker import TTSWorker
from core.tts_engine import TTSEngine
from core.model_manager import ModelManager
from core.audio_processor import AudioProcessor
from core.audio_analyzer import AudioAnalyzer
from core.audio_effects_processor import AudioEffectsProcessor
from core.lip_sync_engine import LipSyncEngine
from core.wav_player import WAVPlayer
from core.whisper_transcriber import WhisperTranscriber

class TTSStudioMainWindow(QMainWindow):
    tts_synthesis_requested = pyqtSignal(str, dict, bool)
    def __init__(self, live2d_url=None, live2d_server_manager=None):
        super().__init__()
        self.live2d_url = live2d_url
        self.live2d_server_manager = live2d_server_manager
        self.tts_engine = TTSEngine()
        self.model_manager = ModelManager()
        self.audio_processor = AudioProcessor()
        self.audio_analyzer = AudioAnalyzer()
        self.audio_effects_processor = AudioEffectsProcessor()
        self.lip_sync_engine = LipSyncEngine()
        self.setup_tts_worker()
        self.wav_player = WAVPlayer()
        self._wav_lipsync_timer = None
        self._wav_lipsync_data = None
        self.whisper_transcriber = WhisperTranscriber(model_size="small", device="cuda")

        
        self.setup_tts_worker()
        
        self.last_generated_audio = None
        self.last_sample_rate = None
        self._tts_busy = False
        
        self.init_ui()
        self.help_dialog = HelpDialog(self)
        self.setup_audio_processing_integration()
        
        # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯çµ±åˆè¨­å®š
        self.setup_lipsync_integration()

        self.setup_wav_playback_integration()
        
        self.sliding_menu = SlidingMenuWidget(self)
        self.sliding_menu.load_model_clicked.connect(self.open_model_loader)
        self.sliding_menu.load_from_history_clicked.connect(self.show_model_history_dialog)
        self.sliding_menu.load_image_clicked.connect(self.character_display.load_character_image)
        self.sliding_menu.load_image_from_history_clicked.connect(self.character_display.show_image_history_dialog)
        self.sliding_menu.load_live2d_clicked.connect(self.character_display.load_live2d_model)
        self.sliding_menu.load_live2d_from_history_clicked.connect(self.character_display.show_live2d_history_dialog)
        self.character_display.live2d_model_loaded.connect(self.on_live2d_model_loaded)
        self.keyboard_shortcuts = KeyboardShortcutManager(self)
        self.load_last_model()

    def init_ui(self):
        self.setWindowTitle("TTSã‚¹ã‚¿ã‚¸ã‚ª - ã»ã®ã‹")
        self.setGeometry(100, 100, 1200, 800)
        self.create_menu_bar()
        central = QWidget()
        self.setCentralWidget(central)
        main = QVBoxLayout(central)
        main.setSpacing(10)
        main.setContentsMargins(15, 15, 15, 15)
        self.main_splitter = QSplitter(Qt.Orientation.Horizontal)
        self.main_splitter.setStyleSheet("""
            QSplitter::handle { background-color: #dee2e6; width: 3px; }
            QSplitter::handle:hover { background-color: #adb5bd; }
        """)
        left_widget = QWidget()
        left_layout = QVBoxLayout(left_widget)
        left_layout.setContentsMargins(0, 0, 0, 0)
        
        # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã¨ã‚¿ãƒ–ã‚¨ãƒªã‚¢ã®é–“ã«ç¸¦æ–¹å‘ã‚¹ãƒ—ãƒªãƒƒã‚¿ãƒ¼ã‚’è¿½åŠ 
        self.vertical_splitter = QSplitter(Qt.Orientation.Vertical)
        self.vertical_splitter.setStyleSheet("""
            QSplitter::handle { background-color: #dee2e6; height: 3px; }
            QSplitter::handle:hover { background-color: #adb5bd; }
        """)
        
        self.multi_text = MultiTextWidget()
        self.multi_text.play_single_requested.connect(self.play_single_text)
        self.multi_text.row_added.connect(self.on_text_row_added)
        self.multi_text.row_removed.connect(self.on_text_row_removed)
        self.multi_text.row_numbers_updated.connect(self.on_row_numbers_updated)
        
        # çµ±åˆã•ã‚ŒãŸã‚¿ãƒ–ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«
        self.tabbed_audio_control = TabbedAudioControl()
        self.tabbed_audio_control.parameters_changed.connect(self.on_parameters_changed)
        self.tabbed_audio_control.cleaner_settings_changed.connect(self.on_cleaner_settings_changed)
        self.tabbed_audio_control.effects_settings_changed.connect(self.on_effects_settings_changed)
        self.tabbed_audio_control.lip_sync_settings_changed.connect(self.on_lipsync_settings_changed)
        # ğŸ†• ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚·ã‚°ãƒŠãƒ«æ¥ç¶š
        self.tabbed_audio_control.modeling_parameter_changed.connect(self.on_modeling_parameter_changed)
        self.tabbed_audio_control.modeling_parameters_changed.connect(self.on_modeling_parameters_changed)
        self.tabbed_audio_control.drag_control_toggled.connect(self.on_drag_control_toggled)
        self.tabbed_audio_control.drag_sensitivity_changed.connect(self.on_drag_sensitivity_changed)
        # çµ±åˆã•ã‚ŒãŸãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯è¨­å®šå¤‰æ›´ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        self.tabbed_audio_control.lip_sync_settings_changed.connect(self.on_lipsync_settings_changed)
        self.tabbed_audio_control.add_text_row("initial", 1)

        self.vertical_splitter.addWidget(self.multi_text)
        self.vertical_splitter.addWidget(self.tabbed_audio_control)

        self.multi_text.setMaximumHeight(360)
        self.vertical_splitter.setSizes([360, 340])
        self.multi_text.setMinimumHeight(40)
        self.tabbed_audio_control.setMinimumHeight(250)

        # æŠ˜ã‚ŠãŸãŸã¿è¨­å®šï¼ˆä¸Šå´ã®ã¿æŠ˜ã‚ŠãŸãŸã¿å¯èƒ½ï¼‰
        self.vertical_splitter.setCollapsible(0, True)
        self.vertical_splitter.setCollapsible(1, False)
        
        controls = QHBoxLayout()
        controls.addStretch()
        self.sequential_play_btn = QPushButton("é€£ç¶šã—ã¦å†ç”Ÿ(Ctrl + R)")
        self.sequential_play_btn.setStyleSheet(self._blue_btn_css())
        self.save_individual_btn = QPushButton("å€‹åˆ¥ä¿å­˜(Ctrl + S)")
        self.save_individual_btn.setStyleSheet(self._green_btn_css())
        self.save_continuous_btn = QPushButton("é€£ç¶šä¿å­˜(Ctrl + Shift + S)")
        self.save_continuous_btn.setStyleSheet(self._orange_btn_css())
        
        # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ†ã‚¹ãƒˆãƒœã‚¿ãƒ³è¿½åŠ 
        self.test_lipsync_btn = QPushButton("ğŸ­ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ†ã‚¹ãƒˆ")
        self.test_lipsync_btn.setStyleSheet("""
            QPushButton { background-color: #6f42c1; color: white; border: none; border-radius: 4px; font-size: 13px; font-weight: bold; padding: 6px 16px; }
            QPushButton:hover:enabled { background-color: #5a359b; }
            QPushButton:pressed:enabled { background-color: #4e2a87; }
            QPushButton:disabled { background-color: #f0f0f0; color: #aaaaaa; }
        """)
        
        for btn in [self.sequential_play_btn, self.save_individual_btn, self.save_continuous_btn, self.test_lipsync_btn]:
            btn.setMinimumHeight(35)
            btn.setEnabled(False)
            controls.addWidget(btn)
            
        self.sequential_play_btn.clicked.connect(self.play_sequential)
        self.save_individual_btn.clicked.connect(self.save_individual)
        self.save_continuous_btn.clicked.connect(self.save_continuous)
        self.test_lipsync_btn.clicked.connect(self.test_lipsync_function)
        
        # å·¦å´ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆçµ„ã¿ç«‹ã¦
        left_layout.addWidget(self.vertical_splitter, 1)
        left_layout.addLayout(controls)
        
        self.character_display = CharacterDisplayWidget(
            live2d_url=self.live2d_url,
            live2d_server_manager=self.live2d_server_manager,
            parent=self
        )
        self.main_splitter.addWidget(left_widget)
        self.main_splitter.addWidget(self.character_display)
        self.main_splitter.setSizes([700, 300])
        left_widget.setMinimumWidth(500)
        self.character_display.setMinimumWidth(200)
        self.main_splitter.splitterMoved.connect(self.on_splitter_moved)
        main.addWidget(self.main_splitter)

    def _blue_btn_css(self) -> str:
        return """
            QPushButton { background-color: #1976d2; color: white; border: none; border-radius: 4px; font-size: 13px; font-weight: bold; padding: 6px 16px; }
            QPushButton:hover:enabled { background-color: #1565c0; }
            QPushButton:pressed:enabled { background-color: #0d47a1; }
            QPushButton:disabled { background-color: #f0f0f0; color: #aaaaaa; }
        """
    def _green_btn_css(self) -> str:
        return """
            QPushButton { background-color: #4caf50; color: white; border: none; border-radius: 4px; font-size: 13px; font-weight: bold; padding: 6px 16px; }
            QPushButton:hover:enabled { background-color: #388e3c; }
            QPushButton:pressed:enabled { background-color: #2e7d32; }
            QPushButton:disabled { background-color: #f0f0f0; color: #aaaaaa; }
        """
    def _orange_btn_css(self) -> str:
        return """
            QPushButton { background-color: #ff9800; color: white; border: none; border-radius: 4px; font-size: 13px; font-weight: bold; padding: 6px 16px; }
            QPushButton:hover:enabled { background-color: #f57c00; }
            QPushButton:pressed:enabled { background-color: #e65100; }
            QPushButton:disabled { background-color: #f0f0f0; color: #aaaaaa; }
        """

    def setup_lipsync_integration(self):
        """ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯æ©Ÿèƒ½ã®çµ±åˆè¨­å®š"""
        try:
            print("ğŸ­ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯æ©Ÿèƒ½çµ±åˆä¸­...")
            
            # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
            if self.lip_sync_engine.is_available():
                print("âœ… ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚¨ãƒ³ã‚¸ãƒ³åˆ©ç”¨å¯èƒ½")
            else:
                print("âš ï¸ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚¨ãƒ³ã‚¸ãƒ³åˆ¶é™ãƒ¢ãƒ¼ãƒ‰ï¼ˆpyopenjtalkä¸ä½¿ç”¨ï¼‰")
                
        except Exception as e:
            print(f"âŒ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯çµ±åˆã‚¨ãƒ©ãƒ¼: {e}")

    def setup_tts_worker(self):
        """TTSåˆæˆã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã®åˆæœŸåŒ–"""
        self.tts_thread = QThread(self)
        self.tts_worker = TTSWorker(self.tts_engine, self.lip_sync_engine)
        self.tts_worker.moveToThread(self.tts_thread)
        self.tts_worker.synthesis_finished.connect(self.on_tts_synthesis_finished)
        self.tts_synthesis_requested.connect(self.tts_worker.synthesize)
        self.tts_thread.finished.connect(self.tts_worker.deleteLater)
        self.tts_thread.start()

    def on_lipsync_settings_changed(self, settings):
        """ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯è¨­å®šå¤‰æ›´æ™‚ã®å‡¦ç† - å®Œå…¨ä¿®æ­£ç‰ˆ"""
        try:
            print(f"ğŸ”§ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯è¨­å®šå¤‰æ›´é–‹å§‹: {list(settings.keys())}")
            
            # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚¨ãƒ³ã‚¸ãƒ³ã«è¨­å®šã‚’é©ç”¨
            if self.lip_sync_engine:
                self.lip_sync_engine.update_settings(settings)
                
                # ãƒ‡ãƒãƒƒã‚°ï¼šç¾åœ¨ã®éŸ³ç´ ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’è¡¨ç¤º
                current_mapping = self.lip_sync_engine.get_vowel_mapping()
                print("ğŸ“Š ã‚¨ãƒ³ã‚¸ãƒ³å´éŸ³ç´ ãƒãƒƒãƒ”ãƒ³ã‚°:")
                for vowel, params in current_mapping.items():
                    if vowel != 'sil':
                        print(f"  {vowel}: é–‹ã={params['mouth_open']}, å½¢={params['mouth_form']}")
            
            # ğŸ”¥ Live2Då´ã«é€ä¿¡ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’ç°¡ç´ åŒ–
            if (hasattr(self.character_display, 'live2d_webview') and 
                self.character_display.live2d_webview.is_model_loaded):
                
                self._send_simple_lipsync_settings(settings)
                
        except Exception as e:
            print(f"âŒ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯è¨­å®šå¤‰æ›´ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()

    def _send_simple_lipsync_settings(self, settings):
        """Live2Då´ã«ã‚·ãƒ³ãƒ—ãƒ«ãªè¨­å®šã‚’é€ä¿¡"""
        try:
            webview = self.character_display.live2d_webview
            
            # ğŸ”¥ ã‚·ãƒ³ãƒ—ãƒ«ãªè¨­å®šãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
            simple_settings = {}
            
            # åŸºæœ¬è¨­å®š
            if 'basic' in settings:
                basic = settings['basic']
                simple_settings['enabled'] = basic.get('enabled', True)
                simple_settings['sensitivity'] = basic.get('sensitivity', 100) / 100.0
                simple_settings['mouth_scale'] = basic.get('mouth_open_scale', 100) / 100.0
            
            # ğŸ”¥ éŸ³ç´ è¨­å®šï¼ˆ0-1ç¯„å›²ã«æ­£è¦åŒ–ï¼‰
            if 'phoneme' in settings:
                simple_settings['vowels'] = {}
                for vowel, params in settings['phoneme'].items():
                    if isinstance(params, dict):
                        # 0-1ç¯„å›²ã«æ­£è¦åŒ–ï¼ˆLive2Dæ¨™æº–ï¼‰
                        mouth_open = max(0, min(1, params.get('mouth_open', 0) / 100.0))
                        mouth_form = max(-1, min(1, params.get('mouth_form', 0) / 100.0))
                        
                        simple_settings['vowels'][vowel] = {
                            'open': round(mouth_open, 3),
                            'form': round(mouth_form, 3)
                        }
                        
                        print(f"  é€ä¿¡: {vowel} = é–‹ã{mouth_open:.3f}, å½¢{mouth_form:.3f}")
            
            # JavaScriptã«é€ä¿¡ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
            import json
            settings_json = json.dumps(simple_settings, ensure_ascii=False)
            
            script = f"""
            (function() {{
                try {{
                    console.log('ğŸ”§ ã‚·ãƒ³ãƒ—ãƒ«è¨­å®šå—ä¿¡:', {settings_json});
                    
                    // ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«ä¿å­˜
                    if (!window.lipSyncSettings) {{
                        window.lipSyncSettings = {{}};
                    }}
                    Object.assign(window.lipSyncSettings, {settings_json});
                    
                    console.log('âœ… è¨­å®šä¿å­˜å®Œäº†:', window.lipSyncSettings);
                    return true;
                }} catch (error) {{
                    console.error('âŒ è¨­å®šä¿å­˜ã‚¨ãƒ©ãƒ¼:', error);
                    return false;
                }}
            }})()
            """
            
            webview.page().runJavaScript(script, self._on_settings_sent)
            
        except Exception as e:
            print(f"âŒ ã‚·ãƒ³ãƒ—ãƒ«è¨­å®šé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")

    def _on_settings_sent(self, result):
        """è¨­å®šé€ä¿¡çµæœã‚’å‡¦ç†"""
        if result:
            print("âœ… Live2Då´è¨­å®šä¿å­˜å®Œäº†")
        else:
            print("âš ï¸ Live2Då´è¨­å®šä¿å­˜å¤±æ•—")

    def test_lipsync_function(self):
        """ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ - éŸ³å£°åŒæœŸç‰ˆ"""
        try:
            print("ğŸ­ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ†ã‚¹ãƒˆé–‹å§‹ï¼ˆéŸ³å£°åŒæœŸç‰ˆï¼‰")
            
            # Live2Dãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if not hasattr(self.character_display, 'live2d_webview') or not self.character_display.live2d_webview.is_model_loaded:
                QMessageBox.warning(self, "ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ†ã‚¹ãƒˆ", 
                    "Live2Dãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
                    "å…ˆã«Live2Dãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã‹ã‚‰ãƒ†ã‚¹ãƒˆã—ã¦ãã ã•ã„ã€‚")
                return
            
            # TTSãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if not self.tts_engine.is_loaded:
                QMessageBox.warning(self, "ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ†ã‚¹ãƒˆ",
                    "éŸ³å£°ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
                    "å…ˆã«éŸ³å£°ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã‹ã‚‰ãƒ†ã‚¹ãƒˆã—ã¦ãã ã•ã„ã€‚")
                return
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            texts_data = self.multi_text.get_all_texts_and_parameters()
            if texts_data and texts_data[0]['text'].strip():
                test_text = texts_data[0]['text']
                row_id = texts_data[0]['row_id']
                test_params = self.tabbed_audio_control.get_parameters(row_id) or texts_data[0]['parameters']
            else:
                test_text = "ã“ã‚“ã«ã¡ã¯ã€‚ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã®ãƒ†ã‚¹ãƒˆã‚’ã—ã¦ã„ã¾ã™ã€‚ã‚ã„ã†ãˆãŠã€‚"
                test_params = {
                    'style': 'Neutral',
                    'style_weight': 1.0,
                    'length_scale': 1.0,
                    'pitch_scale': 1.0,
                    'intonation_scale': 1.0
                }
                
            print(f"ğŸµ ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆ: '{test_text[:30]}...'")
            
            # ãƒœã‚¿ãƒ³çŠ¶æ…‹å¤‰æ›´
            self.test_lipsync_btn.setEnabled(False)
            self.test_lipsync_btn.setText("éŸ³å£°ç”Ÿæˆä¸­...")
            QApplication.processEvents()
            
            # ğŸ”¥ 1. TTSéŸ³å£°ã‚’ç”Ÿæˆ
            sr, audio = self.tts_engine.synthesize(test_text, **test_params)
            print(f"âœ… éŸ³å£°ç”Ÿæˆå®Œäº†: {len(audio)} samples, {sr}Hz, {len(audio)/sr:.3f}ç§’")
            
            self.test_lipsync_btn.setText("è§£æä¸­...")
            QApplication.processEvents()
            
            # ğŸ”¥ 2. ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
            lipsync_data = self.lip_sync_engine.analyze_text_for_lipsync(
                text=test_text,
                audio_data=audio,
                sample_rate=sr
            )
            
            if lipsync_data:
                print(f"âœ… ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ç”ŸæˆæˆåŠŸ: {len(lipsync_data.vowel_frames)}ãƒ•ãƒ¬ãƒ¼ãƒ , {lipsync_data.total_duration:.3f}ç§’")
                
                # éŸ³å£°ã‚’å†ç”Ÿ
                import sounddevice as sd
                sd.play(audio, sr, blocking=False)
                
                # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚’é€ä¿¡
                self.send_lipsync_to_live2d(lipsync_data)
                
                self.test_lipsync_btn.setText("ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
                
                # ã‚¿ã‚¤ãƒãƒ¼ã§åœæ­¢
                QTimer.singleShot(int(lipsync_data.total_duration * 1000) + 500, self._reset_test_button)
                
            else:
                print("âŒ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå¤±æ•—")
                QMessageBox.warning(self, "ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ†ã‚¹ãƒˆ", "ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                self._reset_test_button()
                
        except Exception as e:
            print(f"âŒ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            QMessageBox.critical(self, "ã‚¨ãƒ©ãƒ¼", f"ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n{str(e)}")
            self._reset_test_button()

    def _reset_test_button(self):
        """ãƒ†ã‚¹ãƒˆãƒœã‚¿ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self.test_lipsync_btn.setEnabled(True)
        self.test_lipsync_btn.setText("ğŸ­ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ†ã‚¹ãƒˆ")

    def send_lipsync_to_live2d(self, lipsync_data):
        """Live2Dã«ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡ - ä½ç½®ãƒªã‚»ãƒƒãƒˆé˜²æ­¢ç‰ˆ"""
        try:
            print(f"ğŸ­ Live2Dãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é€ä¿¡: {len(lipsync_data.vowel_frames)}ãƒ•ãƒ¬ãƒ¼ãƒ , {lipsync_data.total_duration:.3f}ç§’")
            
            # ğŸ”§ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é–‹å§‹ï¼šä½ç½®ãƒªã‚»ãƒƒãƒˆé˜²æ­¢ã‚’æœ‰åŠ¹åŒ–
            self.character_display.mark_lipsync_in_progress(True)
            
            # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ãƒ¼ã‚¿æº–å‚™
            simple_data = {
                'text': lipsync_data.text,
                'duration': lipsync_data.total_duration,
                'frames': [
                    {
                        'time': frame.timestamp,
                        'vowel': frame.vowel,
                        'intensity': frame.intensity,
                        'duration': frame.duration
                    }
                    for frame in lipsync_data.vowel_frames
                ]
            }
            
            webview = self.character_display.live2d_webview
            
            import json
            data_json = json.dumps(simple_data, ensure_ascii=False)

            script = f"""
            (function() {{
                try {{
                    const lipSyncData = {data_json};
                    console.log('ğŸ­ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿å—ä¿¡:', lipSyncData.frames.length, 'ãƒ•ãƒ¬ãƒ¼ãƒ ');
                    
                    if (typeof window.startSimpleLipSync === 'function') {{
                        return window.startSimpleLipSync(lipSyncData);
                    }} else if (typeof window.startLipSync === 'function') {{
                        return window.startLipSync(lipSyncData);
                    }} else {{
                        console.error('âŒ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é–¢æ•°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
                        return false;
                    }}
                }} catch (error) {{
                    console.error('âŒ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é€ä¿¡ã‚¨ãƒ©ãƒ¼:', error);
                    return false;
                }}
            }})()
            """
            
            # JavaScriptã«ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é–‹å§‹å‘½ä»¤ã‚’é€ä¿¡
            webview.page().runJavaScript(script)

            # â˜…â˜…â˜… è¿½åŠ ã—ãŸè¡Œ â˜…â˜…â˜…
            # JSå‘¼ã³å‡ºã—ç›´å¾Œ(10ãƒŸãƒªç§’å¾Œ)ã«ã€ç¾åœ¨ã®UIã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®è¨­å®šã‚’å¼·åˆ¶çš„ã«å†åŒæœŸã•ã›ã‚‹
            QTimer.singleShot(10, self.character_display.sync_current_live2d_settings_to_webview)
            
            # ğŸ”§ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯çµ‚äº†å¾Œã«ä½ç½®ãƒªã‚»ãƒƒãƒˆé˜²æ­¢ã‚’ç„¡åŠ¹åŒ–ï¼ˆã‚¿ã‚¤ãƒãƒ¼ï¼‰
            QTimer.singleShot(int(lipsync_data.total_duration * 1000) + 500, 
                            lambda: self.character_display.mark_lipsync_in_progress(False))

        except Exception as e:
            print(f"âŒ Live2Dãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚å¿…ãšç„¡åŠ¹åŒ–
            self.character_display.mark_lipsync_in_progress(False)

    def create_menu_bar(self):
        menubar = self.menuBar()
        menubar.setStyleSheet("""
            QMenuBar { background-color: #f8f9fa; color: #333; border-bottom: 1px solid #dee2e6; padding: 4px; }
            QMenuBar::item { background-color: transparent; padding: 6px 12px; margin: 0px 2px; border-radius: 4px; }
            QMenuBar::item:selected { background-color: #e9ecef; }
            QMenuBar::item:pressed { background-color: #dee2e6; }
        """)
        menubar.addAction("ãƒ•ã‚¡ã‚¤ãƒ«(F)").triggered.connect(self.toggle_file_menu)
        menubar.addAction("èª¬æ˜(H)").triggered.connect(self.show_help_dialog)
        
    def show_help_dialog(self):
        self.help_dialog.show()
        self.help_dialog.raise_()
        self.help_dialog.activateWindow()
        
    def toggle_file_menu(self):
        self.sliding_menu.toggle_menu()
        
    def mousePressEvent(self, event):
        if self.sliding_menu.is_visible and not self.sliding_menu.geometry().contains(event.pos()):
            self.sliding_menu.hide_menu()
        super().mousePressEvent(event)
        
    def on_splitter_moved(self, pos, index):
        if hasattr(self, 'main_splitter'):
            sizes = self.main_splitter.sizes()
            total_width = sum(sizes)
            max_right_width = total_width * 0.3
            min_left_width = total_width * 0.7
            if len(sizes) >= 2:
                left_width, right_width = sizes[0], sizes[1]
                if right_width > max_right_width:
                    new_right_width = int(max_right_width)
                    new_left_width = total_width - new_right_width
                    self.main_splitter.setSizes([new_left_width, new_right_width])
                elif left_width < min_left_width:
                    new_left_width = int(min_left_width)
                    new_right_width = total_width - new_left_width
                    self.main_splitter.setSizes([new_left_width, new_right_width])
                    
    def resizeEvent(self, event):
        super().resizeEvent(event)
        
    def on_live2d_model_loaded(self, model_path):
        self.character_display.live2d_model_loaded.connect(self.on_live2d_model_loaded)
        # ğŸ†• ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†ã‚·ã‚°ãƒŠãƒ«æ¥ç¶š
        self.character_display.live2d_parameters_loaded.connect(self.on_live2d_parameters_loaded)
        model_name = Path(model_path).name
        print(f"Live2Dãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ: {model_name}")
        current_title = self.windowTitle()
        if " - " in current_title:
            base_title = current_title.split(" - ")[0]
        else:
            base_title = current_title
        self.setWindowTitle(f"{base_title} - {model_name} (Live2D)")
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ç›´å¾Œã«ãƒ‰ãƒ©ãƒƒã‚°åˆ¶å¾¡ã®çŠ¶æ…‹ã‚’åŒæœŸ
        QTimer.singleShot(100, self.sync_drag_control_state)

    def setup_audio_processing_integration(self):
            self.tabbed_audio_control.cleaner_control.analyze_requested.connect(self.handle_cleaner_analysis_request)
        
    # ========================================
    # ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: ui/main_window.py
    # ğŸ“ å ´æ‰€: setup_wav_playback_integration() ãƒ¡ã‚½ãƒƒãƒ‰å†…ã€æ—¢å­˜ã‚·ã‚°ãƒŠãƒ«æ¥ç¶šã®ä¸‹
    # ========================================

    def setup_wav_playback_integration(self):
        """WAVå†ç”Ÿæ©Ÿèƒ½ã®çµ±åˆè¨­å®š"""
        try:
            print("ğŸµ WAVå†ç”Ÿæ©Ÿèƒ½çµ±åˆä¸­...")
            
            # æ—¢å­˜ã®ã‚·ã‚°ãƒŠãƒ«æ¥ç¶š...
            self.tabbed_audio_control.wav_file_loaded.connect(self.on_wav_file_loaded)
            self.tabbed_audio_control.wav_playback_started.connect(self.on_wav_playback_started)
            self.tabbed_audio_control.wav_playback_paused.connect(self.on_wav_playback_paused)
            self.tabbed_audio_control.wav_playback_stopped.connect(self.on_wav_playback_stopped)
            self.tabbed_audio_control.wav_position_changed.connect(self.on_wav_position_changed)
            self.tabbed_audio_control.wav_volume_changed.connect(self.on_wav_volume_changed)
            
            # WAVãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚·ã‚°ãƒŠãƒ«æ¥ç¶š
            self.wav_player.playback_position_changed.connect(self.on_wav_player_position_update)
            self.wav_player.playback_finished.connect(self.on_wav_player_finished)
            
            # ğŸ†• æ–‡å­—èµ·ã“ã—é–¢é€£ã‚·ã‚°ãƒŠãƒ«æ¥ç¶š
            wav_control = self.tabbed_audio_control.get_wav_playback_control()
            wav_control.re_analyze_requested.connect(self.on_wav_reanalyze_requested)
            wav_control.save_transcription_requested.connect(self.on_save_transcription_requested)  # ğŸ†• è¿½åŠ 
            
            print("âœ… WAVå†ç”Ÿæ©Ÿèƒ½çµ±åˆå®Œäº†")
            
        except Exception as e:
            print(f"âŒ WAVå†ç”Ÿçµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
        
    def handle_cleaner_analysis_request(self):
        if not self.tts_engine.is_loaded:
            QMessageBox.warning(self, "ã‚¨ãƒ©ãƒ¼", "ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\nå…ˆã«ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã‹ã‚‰è§£æã—ã¦ãã ã•ã„ã€‚")
            return
        self.generate_test_audio_for_analysis()
        
    def generate_test_audio_for_analysis(self):
        texts_data = self.multi_text.get_all_texts_and_parameters()
        if texts_data and texts_data[0]['text'].strip():
            first_data = texts_data[0]
            test_text = first_data['text']
            row_id = first_data['row_id']
            test_params = self.tabbed_audio_control.get_parameters(row_id) or first_data['parameters']
        else:
            test_text = "ã“ã‚Œã¯éŸ³å£°è§£æç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚ã»ã®ã‹ã¡ã‚ƒã‚“ã®å£°ã§å“è³ªã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚"
            test_params = { 'style': 'Neutral', 'style_weight': 1.0, 'length_scale': 0.85, 'pitch_scale': 1.0, 'intonation_scale': 1.0, 'sdp_ratio': 0.25, 'noise': 0.35 }
            print("âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆãŒæœªå…¥åŠ›ã®ãŸã‚ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨")
        progress = None
        try:
            progress = QMessageBox(self)
            progress.setWindowTitle("éŸ³å£°ç”Ÿæˆä¸­")
            progress.setText(f"è§£æç”¨ã®éŸ³å£°ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...\n\nãƒ†ã‚­ã‚¹ãƒˆ: {test_text[:50]}...")
            progress.setStandardButtons(QMessageBox.StandardButton.NoButton)
            progress.setWindowModality(Qt.WindowModality.ApplicationModal)
            progress.show()
            QApplication.processEvents()
            sr, audio = self.tts_engine.synthesize(test_text, **test_params)
            self.last_generated_audio = audio
            self.last_sample_rate = sr
            if progress: progress.close()
            QApplication.processEvents()
            self.tabbed_audio_control.cleaner_control.set_audio_data_for_analysis(audio, sr)
        except Exception as e:
            if progress: progress.close()
            QApplication.processEvents()
            QMessageBox.critical(self, "ã‚¨ãƒ©ãƒ¼", f"è§£æç”¨éŸ³å£°ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ:\n{str(e)}")
        finally:
            if progress: progress.deleteLater()
            
    def open_model_loader(self):
        dialog = ModelLoaderDialog(self)
        dialog.model_loaded.connect(self.load_model)
        dialog.exec()
        
    def show_model_history_dialog(self):
        from PyQt6.QtWidgets import QDialog, QVBoxLayout
        if not self.model_manager.get_all_models():
            QMessageBox.information(self, "å±¥æ­´ãªã—", "ãƒ¢ãƒ‡ãƒ«å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        dlg = QDialog(self)
        dlg.setWindowTitle("ãƒ¢ãƒ‡ãƒ«å±¥æ­´ã‹ã‚‰é¸æŠ")
        dlg.setModal(True)
        dlg.resize(560, 420)
        dlg.setStyleSheet("QDialog { background:#f8f9fa; }")
        lay = QVBoxLayout(dlg)
        widget = ModelHistoryWidget(self.model_manager, dlg)
        def _on_selected(model_data):
            if not self.model_manager.validate_model_files(model_data):
                QMessageBox.warning(dlg, "ã‚¨ãƒ©ãƒ¼", "ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                return
            paths = {k: model_data[k] for k in ['model_path', 'config_path', 'style_path']}
            dlg.accept()
            self.load_model(paths)
        widget.model_selected.connect(_on_selected)
        lay.addWidget(widget)
        dlg.exec()
        
    def load_model(self, paths):
        try:
            if self.tts_engine.load_model(**paths):
                self.model_manager.add_model(**paths)
                for btn in [self.sequential_play_btn, self.save_individual_btn, self.save_continuous_btn, self.test_lipsync_btn]:
                    btn.setEnabled(True)
                model_name = Path(paths["model_path"]).parent.name
                if hasattr(self.character_display, 'current_live2d_folder') and self.character_display.current_live2d_folder:
                    live2d_name = Path(self.character_display.current_live2d_folder).name
                    self.setWindowTitle(f"TTSã‚¹ã‚¿ã‚¸ã‚ª - {model_name} - {live2d_name} (Live2D)")
                else:
                    self.setWindowTitle(f"TTSã‚¹ã‚¿ã‚¸ã‚ª - {model_name}")
                available_styles = self.tts_engine.get_available_styles()
                QMessageBox.information(self, "æˆåŠŸ", f"ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚\n\nğŸ­ åˆ©ç”¨å¯èƒ½æ„Ÿæƒ…: {len(available_styles)}å€‹")
                self.update_emotion_ui_after_model_load()
            else:
                QMessageBox.critical(self, "ã‚¨ãƒ©ãƒ¼", "ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            QMessageBox.critical(self, "ã‚¨ãƒ©ãƒ¼", f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n{str(e)}")

    def load_last_model(self):
        """ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã®è‡ªå‹•å¾©å…ƒï¼šéŸ³å£°ãƒ¢ãƒ‡ãƒ« + Live2Dãƒ¢ãƒ‡ãƒ«"""
        # 1. éŸ³å£°ãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•å¾©å…ƒ
        models = self.model_manager.get_all_models()
        if models:
            last = models[0]
            if self.model_manager.validate_model_files(last):
                paths = {k: last[k] for k in ["model_path", "config_path", "style_path"]}
                if self.tts_engine.load_model(**paths):
                    for btn in [self.sequential_play_btn, self.save_individual_btn, self.save_continuous_btn, self.test_lipsync_btn]:
                        btn.setEnabled(True)
                    model_name = Path(paths["model_path"]).parent.name
                    self.setWindowTitle(f"TTSã‚¹ã‚¿ã‚¸ã‚ª - {model_name}")
                    self.update_emotion_ui_after_model_load()
                    print(f"âœ… éŸ³å£°ãƒ¢ãƒ‡ãƒ«è‡ªå‹•å¾©å…ƒå®Œäº†: {model_name}")
        
        # 2. Live2Dãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•å¾©å…ƒ
        self.load_last_live2d_model()

    def load_last_live2d_model(self):
        """æœ€å¾Œã«ä½¿ç”¨ã—ãŸLive2Dãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•å¾©å…ƒ"""
        try:
            if hasattr(self.character_display, 'live2d_manager'):
                last_live2d = self.character_display.live2d_manager.get_last_model()
                
                if last_live2d:
                    model_folder_path = last_live2d['model_folder_path']
                    
                    if Path(model_folder_path).exists():
                        validation = self.character_display.live2d_manager.validate_model_folder(model_folder_path)
                        
                        if validation['is_valid']:
                            self.character_display.load_live2d_model_from_data(last_live2d)
                        else:
                            print(f"âš ï¸ Live2Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸å®Œå…¨: {model_folder_path}")
                    else:
                        print(f"âš ï¸ Live2Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_folder_path}")
                else:
                    print("â„¹ï¸ Live2Då±¥æ­´ãªã—")
        except Exception as e:
            print(f"Live2Dè‡ªå‹•å¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")

    def apply_audio_cleaning(self, audio, sample_rate):
        if not self.tabbed_audio_control.is_cleaner_enabled(): return audio
        try:
            settings = self.tabbed_audio_control.get_cleaner_settings()
            return self.audio_processor.process_audio(audio, sample_rate, settings)
        except Exception as e:
            print(f"éŸ³å£°ã‚¯ãƒªãƒ¼ãƒŠãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
            return audio
            
    def apply_audio_effects(self, audio, sample_rate):
        if not self.tabbed_audio_control.is_effects_enabled(): return audio
        try:
            settings = self.tabbed_audio_control.get_effects_settings()
            return self.audio_effects_processor.process_effects(audio, sample_rate, settings)
        except Exception as e:
            print(f"éŸ³å£°ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return audio
            
    def play_single_text(self, row_id, text, parameters):
        """å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆå†ç”Ÿï¼ˆãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯çµ±åˆç‰ˆï¼‰"""
        if not self.tts_engine.is_loaded:
            QMessageBox.warning(self, "ã‚¨ãƒ©ãƒ¼", "ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return
        
        if self._tts_busy:
            print("â³ åˆ¥ã®éŸ³å£°åˆæˆå‡¦ç†ãŒå®Ÿè¡Œä¸­ã®ãŸã‚å¾…æ©Ÿã—ã¦ãã ã•ã„ã€‚")
            return
        
        tab_parameters = self.tabbed_audio_control.get_parameters(row_id) or parameters

        self._tts_busy = True
        enable_lipsync = self.tabbed_audio_control.is_lip_sync_enabled()
        self.tts_synthesis_requested.emit(text, tab_parameters, enable_lipsync)

    def on_tts_synthesis_finished(self, sample_rate, audio, lipsync_data, error_message):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰ã®åˆæˆçµæœã‚’å—ã‘å–ã‚ŠUIå´ã®å‡¦ç†ã‚’è¡Œã†"""
        self._tts_busy = False

        if error_message:
            print(error_message)
            QMessageBox.critical(self, "ã‚¨ãƒ©ãƒ¼", "éŸ³å£°åˆæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚\nè©³ç´°ã¯ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return

        if audio is None or sample_rate is None:
            return
        
        try:
            audio = self.apply_audio_cleaning(audio, sample_rate)
            audio = self.apply_audio_effects(audio, sample_rate)
            self.last_generated_audio, self.last_sample_rate = audio, sample_rate

            # éŸ³å£°å†ç”Ÿ
            import sounddevice as sd
            sd.play(audio, sample_rate, blocking=False)

            # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é€ä¿¡
            if (lipsync_data and
                self.tabbed_audio_control.is_lip_sync_enabled() and
                hasattr(self.character_display, 'live2d_webview') and
                self.character_display.live2d_webview.is_model_loaded):
                
                self.send_lipsync_to_live2d(lipsync_data)
                print(f"ğŸ­ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å®Ÿè¡Œ: {len(lipsync_data.vowel_frames)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
            
        except Exception as e:
            QMessageBox.critical(self, "ã‚¨ãƒ©ãƒ¼", f"éŸ³å£°å†ç”Ÿå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            
    def trim_silence(self, audio, sample_rate, threshold=0.01):
        non_silent = np.where(np.abs(audio) > threshold)[0]
        if len(non_silent) > 0:
            return audio[:non_silent[-1] + int(sample_rate * 0.1)]
        return audio
        
    def _synthesize_and_process_all(self):
        texts_data = self.multi_text.get_all_texts_and_parameters()
        if not texts_data:
            QMessageBox.information(self, "æƒ…å ±", "å‡¦ç†ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return None, None
        all_audio, sample_rate = [], None
        for data in texts_data:
            params = self.tabbed_audio_control.get_parameters(data['row_id']) or data['parameters']
            sr, audio = self.tts_engine.synthesize(data['text'], **params)
            if sample_rate is None: sample_rate = sr
            audio = self.apply_audio_cleaning(audio, sr)
            audio = self.apply_audio_effects(audio, sr)
            audio = self.trim_silence(audio, sr)
            all_audio.append(audio)
        final_audio = np.concatenate(all_audio).astype(np.float32)
        max_val = np.abs(final_audio).max()
        if max_val > 0.9: final_audio *= 0.9 / max_val
        self.last_generated_audio, self.last_sample_rate = final_audio, sample_rate
        return final_audio, sample_rate
        
    def play_sequential(self):
        if not self.tts_engine.is_loaded: return
        self.sequential_play_btn.setEnabled(False)
        final_audio, sr = self._synthesize_and_process_all()
        self.sequential_play_btn.setEnabled(True)
        if final_audio is not None:
            import sounddevice as sd
            sd.play(final_audio, sr, blocking=False)
            
    def save_individual(self):
        folder_path = QFileDialog.getExistingDirectory(self, "å€‹åˆ¥ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠ")
        if not folder_path: return
        import soundfile as sf
        texts_data = self.multi_text.get_all_texts_and_parameters()
        self.save_individual_btn.setEnabled(False)
        for i, data in enumerate(texts_data, 1):
            params = self.tabbed_audio_control.get_parameters(data['row_id']) or data['parameters']
            sr, audio = self.tts_engine.synthesize(data['text'], **params)
            audio = self.apply_audio_cleaning(audio, sr)
            audio = self.apply_audio_effects(audio, sr)
            safe_text = "".join(c for c in data['text'][:20] if c.isalnum() or c in " -_").rstrip() or f"text_{i}"
            filename = f"{i:02d}_{safe_text}.wav"
            sf.write(os.path.join(folder_path, filename), audio, sr)
        self.save_individual_btn.setEnabled(True)
        QMessageBox.information(self, "å®Œäº†", f"å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
        
    def save_continuous(self):
        file_path, _ = QFileDialog.getSaveFileName(self, "é€£ç¶šéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜", "continuous.wav", "WAV files (*.wav)")
        if not file_path: return
        self.save_continuous_btn.setEnabled(False)
        final_audio, sr = self._synthesize_and_process_all()
        self.save_continuous_btn.setEnabled(True)
        if final_audio is not None:
            import soundfile as sf
            sf.write(file_path, final_audio, sr)
            QMessageBox.information(self, "å®Œäº†", f"é€£ç¶šéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
            
    def on_text_row_added(self, row_id, row_number):
        self.tabbed_audio_control.add_text_row(row_id, row_number)
        
    def on_text_row_removed(self, row_id):
        self.tabbed_audio_control.remove_text_row(row_id)
        
    def on_row_numbers_updated(self, row_mapping):
        self.tabbed_audio_control.update_tab_numbers(row_mapping)
        
    def on_parameters_changed(self, row_id, parameters): pass
    def on_cleaner_settings_changed(self, cleaner_settings): pass
    def on_effects_settings_changed(self, effects_settings): pass
    
    def update_emotion_ui_after_model_load(self):
        if not self.tts_engine.is_loaded: return
        try:
            styles = self.tts_engine.get_available_styles()
            self.tabbed_audio_control.emotion_control.update_emotion_list(styles)
        except Exception as e:
            print(f"æ„Ÿæƒ…UIæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
            
    def closeEvent(self, event):
        try:
            cleaner_control = self.tabbed_audio_control.cleaner_control
            if hasattr(cleaner_control, 'analysis_thread') and cleaner_control.analysis_thread and cleaner_control.analysis_thread.isRunning():
                cleaner_control.analysis_thread.quit()
                cleaner_control.analysis_thread.wait(3000)
            if self.tts_engine: self.tts_engine.unload_model()
            self.model_manager.save_history()
            if hasattr(self.character_display, 'live2d_manager'):
                self.character_display.live2d_manager.save_history()
            if hasattr(self, 'tts_thread') and self.tts_thread.isRunning():
                self.tts_thread.quit()
                self.tts_thread.wait(5000)
                self.character_display.live2d_manager.save_history()
        except Exception as e:
            print(f"çµ‚äº†å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        event.accept()

    # ================================
    # ğŸ†• ãƒ¢ãƒ‡ãƒªãƒ³ã‚°é–¢é€£ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    # ================================
    
    def on_live2d_parameters_loaded(self, parameters: list, model_id: str):
        """Live2Dãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†æ™‚"""
        try:
            print(f"ğŸ¨ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(parameters)}å€‹")
            self.tabbed_audio_control.load_model_parameters(parameters, model_id)
        except Exception as e:
            print(f"âŒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    def on_modeling_parameter_changed(self, param_id: str, value: float):
        """ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰æ›´æ™‚ï¼ˆå˜ä¸€ï¼‰"""
        try:
            if hasattr(self.character_display, 'set_live2d_parameter'):
                self.character_display.set_live2d_parameter(param_id, value)
        except Exception as e:
            print(f"âŒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã‚¨ãƒ©ãƒ¼ ({param_id}): {e}")
    
    def on_modeling_parameters_changed(self, parameters: dict):
        """ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰æ›´æ™‚ï¼ˆå…¨ä½“ï¼‰"""
        try:
            if hasattr(self.character_display, 'set_live2d_parameters'):
                self.character_display.set_live2d_parameters(parameters)
        except Exception as e:
            print(f"âŒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸€æ‹¬è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")

    def on_drag_control_toggled(self, enabled: bool):
        """ãƒ‰ãƒ©ãƒƒã‚°åˆ¶å¾¡ON/OFFåˆ‡ã‚Šæ›¿ãˆ"""
        try:
            if hasattr(self.character_display, 'enable_drag_control'):
                self.character_display.enable_drag_control(enabled)
        except Exception as e:
            print(f"âŒ ãƒ‰ãƒ©ãƒƒã‚°åˆ¶å¾¡åˆ‡ã‚Šæ›¿ãˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def on_drag_sensitivity_changed(self, sensitivity: float):
        """ãƒ‰ãƒ©ãƒƒã‚°æ„Ÿåº¦å¤‰æ›´"""
        try:
            if hasattr(self.character_display, 'set_drag_sensitivity'):
                self.character_display.set_drag_sensitivity(sensitivity)
        except Exception as e:
            print(f"âŒ ãƒ‰ãƒ©ãƒƒã‚°æ„Ÿåº¦å¤‰æ›´ã‚¨ãƒ©ãƒ¼: {e}")

    def sync_drag_control_state(self):
        """UIã¨Live2Dãƒ‰ãƒ©ãƒƒã‚°åˆ¶å¾¡ã®çŠ¶æ…‹ã‚’åŒæœŸ"""
        modeling_control = getattr(self.tabbed_audio_control, 'modeling_control', None)
        if not modeling_control:
            return

        try:
            self.on_drag_control_toggled(modeling_control.is_drag_enabled())
        except Exception as e:
            print(f"âš ï¸ ãƒ‰ãƒ©ãƒƒã‚°åˆ¶å¾¡çŠ¶æ…‹åŒæœŸã‚¨ãƒ©ãƒ¼: {e}")

        try:
            self.on_drag_sensitivity_changed(modeling_control.get_drag_sensitivity())
        except Exception as e:
            print(f"âš ï¸ ãƒ‰ãƒ©ãƒƒã‚°æ„Ÿåº¦åŒæœŸã‚¨ãƒ©ãƒ¼: {e}")
    
    # ========================================
    # ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: ui/main_window.py
    # ğŸ“ å ´æ‰€: on_wav_file_loaded() ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Œå…¨ã«ç½®ãæ›ãˆ
    # ========================================

    def on_wav_file_loaded(self, file_path: str):
        """WAVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†ï¼ˆWhisperæ–‡å­—èµ·ã“ã—çµ±åˆç‰ˆï¼‰"""
        try:
            print(f"ğŸµ WAVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿é–‹å§‹: {file_path}")
            
            # WAVãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§èª­ã¿è¾¼ã¿
            if not self.wav_player.load_wav_file(file_path):
                QMessageBox.warning(self, "ã‚¨ãƒ©ãƒ¼", "WAVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                return
            
            # UIå´ã«é•·ã•ã‚’é€šçŸ¥
            duration = self.wav_player.get_duration()
            wav_control = self.tabbed_audio_control.get_wav_playback_control()
            wav_control.set_duration(duration)
            
            print(f"âœ… WAVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {duration:.2f}ç§’")
            
            # ğŸ†• Whisperã«ã‚ˆã‚‹æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
            if self.whisper_transcriber.is_ready():
                self._transcribe_and_generate_lipsync(file_path, wav_control)
            else:
                # Whisperåˆ©ç”¨ä¸å¯æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                print("âš ï¸ Whisperåˆ©ç”¨ä¸å¯ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰")
                wav_control.set_transcription_status("âš ï¸ faster-whisperãŒåˆ©ç”¨ã§ãã¾ã›ã‚“", is_processing=False)
                self._generate_wav_lipsync_data_with_text(file_path, "ã“ã‚“ã«ã¡ã¯")
            
        except Exception as e:
            print(f"âŒ WAVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            QMessageBox.critical(self, "ã‚¨ãƒ©ãƒ¼", f"WAVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼:\n{str(e)}")


    def _transcribe_and_generate_lipsync(self, file_path: str, wav_control):
        """Whisperæ–‡å­—èµ·ã“ã— + ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ç”Ÿæˆ"""
        try:
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºæ›´æ–°
            wav_control.set_transcription_status("ğŸ¤ éŸ³å£°èªè­˜å‡¦ç†ä¸­...", is_processing=True)
            QApplication.processEvents()
            
            # Whisperã§æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
            success, transcribed_text, segments = self.whisper_transcriber.transcribe_wav(
                file_path, 
                language="ja"
            )
            
            if success:
                print(f"âœ… æ–‡å­—èµ·ã“ã—æˆåŠŸ: {transcribed_text[:50]}...")
                
                # UIã«ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºï¼ˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãï¼‰
                wav_control.set_transcription_text(transcribed_text, segments, animated=True)  # ğŸ†• animated=True
                wav_control.set_transcription_status("âœ… æ–‡å­—èµ·ã“ã—å®Œäº†", is_processing=False)
                
                # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
                self._generate_wav_lipsync_data_with_text(file_path, transcribed_text)
                
                # ğŸ†• è‡ªå‹•ä¿å­˜ï¼ˆè¿½è¨˜å‹ï¼‰
                self._auto_save_transcription(file_path, segments)
                
            else:
                # ã‚¨ãƒ©ãƒ¼æ™‚
                error_msg = transcribed_text
                print(f"âŒ æ–‡å­—èµ·ã“ã—å¤±æ•—: {error_msg}")
                wav_control.set_transcription_status(f"âŒ ã‚¨ãƒ©ãƒ¼: {error_msg[:30]}...", is_processing=False)
                
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                self._generate_wav_lipsync_data_with_text(file_path, "ã“ã‚“ã«ã¡ã¯")
            
        except Exception as e:
            print(f"âŒ æ–‡å­—èµ·ã“ã—å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            
            wav_control.set_transcription_status("âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼", is_processing=False)
            self._generate_wav_lipsync_data_with_text(file_path, "ã“ã‚“ã«ã¡ã¯")


    # ğŸ“ æ–°è¦ãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ ï¼ˆ_transcribe_and_generate_lipsync ã®ä¸‹ï¼‰

    def _auto_save_transcription(self, wav_path: str, segments: list):
        """æ–‡å­—èµ·ã“ã—çµæœã‚’è‡ªå‹•ä¿å­˜ï¼ˆè¿½è¨˜å‹ï¼‰
        
        Args:
            wav_path: å…ƒã®WAVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            segments: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆ
        """
        try:
            if not segments:
                return
            
            # ä¿å­˜å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            transcription_file = Path("transcriptions.txt")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
            file_name = Path(wav_path).name
            
            # è¿½è¨˜ãƒ¢ãƒ¼ãƒ‰ã§ä¿å­˜
            success = self.whisper_transcriber.save_transcription_to_file(
                segments,
                str(transcription_file),
                include_timestamps=True,
                append_mode=True,  # ğŸ†• è¿½è¨˜ãƒ¢ãƒ¼ãƒ‰
                file_name=file_name  # ğŸ†• ãƒ˜ãƒƒãƒ€ãƒ¼ç”¨
            )
            
            if success:
                print(f"ğŸ’¾ è‡ªå‹•ä¿å­˜å®Œäº†: {transcription_file}")
            
        except Exception as e:
            print(f"âš ï¸ è‡ªå‹•ä¿å­˜ã‚¨ãƒ©ãƒ¼ï¼ˆå‡¦ç†ã¯ç¶™ç¶šï¼‰: {e}")

    def _generate_wav_lipsync_data_with_text(self, file_path: str, text: str):
        """æŒ‡å®šã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã§WAVå…¨ä½“ã®ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        
        Args:
            file_path: WAVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            text: ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ç”¨ãƒ†ã‚­ã‚¹ãƒˆ
        """
        try:
            print(f"ğŸ­ WAVãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯è§£æé–‹å§‹: '{text[:50]}...'")
            
            audio_data = self.wav_player.get_audio_data()
            sample_rate = self.wav_player.get_sample_rate()
            
            if audio_data is None or sample_rate is None:
                print("âš ï¸ éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“")
                return
            
            # ğŸ”¥ å®Ÿéš›ã®ãƒ†ã‚­ã‚¹ãƒˆã§ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯è§£æå®Ÿè¡Œ
            self._wav_lipsync_data = self.lip_sync_engine.analyze_text_for_lipsync(
                text=text,
                audio_data=audio_data,
                sample_rate=sample_rate
            )
            
            if self._wav_lipsync_data:
                print(f"âœ… WAVãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯è§£æå®Œäº†: {len(self._wav_lipsync_data.vowel_frames)}ãƒ•ãƒ¬ãƒ¼ãƒ , {self._wav_lipsync_data.total_duration:.3f}ç§’")
            else:
                print("âš ï¸ WAVãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯è§£æå¤±æ•—")
                
        except Exception as e:
            print(f"âŒ WAVãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯è§£æã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()


    def on_wav_reanalyze_requested(self, edited_text: str):
        """å†è§£æãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯æ™‚ï¼ˆãƒ†ã‚­ã‚¹ãƒˆç·¨é›†å¾Œï¼‰
        
        Args:
            edited_text: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç·¨é›†ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        try:
            print(f"ğŸ”„ WAVãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å†è§£æ: '{edited_text[:50]}...'")
            
            wav_control = self.tabbed_audio_control.get_wav_playback_control()
            
            # å†è§£æä¸­è¡¨ç¤º
            wav_control.set_transcription_status("ğŸ”„ å†è§£æä¸­...", is_processing=True)
            QApplication.processEvents()
            
            # ç¾åœ¨ã®WAVãƒ•ã‚¡ã‚¤ãƒ«ã§å†è§£æ
            current_file = wav_control.get_current_file_path()
            if current_file:
                self._generate_wav_lipsync_data_with_text(current_file, edited_text)
                wav_control.set_transcription_status("âœ… å†è§£æå®Œäº†", is_processing=False)
            else:
                print("âš ï¸ WAVãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                wav_control.set_transcription_status("âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«æœªèª­ã¿è¾¼ã¿", is_processing=False)
            
        except Exception as e:
            print(f"âŒ WAVå†è§£æã‚¨ãƒ©ãƒ¼: {e}")
            wav_control.set_transcription_status("âŒ å†è§£æã‚¨ãƒ©ãƒ¼", is_processing=False)

    # ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: ui/main_window.py
    # ğŸ“ å ´æ‰€: æ–°è¦ãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ ï¼ˆon_wav_reanalyze_requested ã®ä¸‹ï¼‰

    def on_save_transcription_requested(self):
        """ğŸ’¾ æ–‡å­—èµ·ã“ã—ä¿å­˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        try:
            wav_control = self.tabbed_audio_control.get_wav_playback_control()
            
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            segments = wav_control.transcription_segments
            if not segments:
                QMessageBox.warning(self, "ã‚¨ãƒ©ãƒ¼", "ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return
            
            # ä¿å­˜å…ˆã‚’é¸æŠ
            current_file = wav_control.get_current_file_path()
            default_name = Path(current_file).stem + "_transcription.txt" if current_file else "transcription.txt"
            
            file_path, _ = QFileDialog.getSaveFileName(
                self,
                "æ–‡å­—èµ·ã“ã—ã‚’ä¿å­˜",
                default_name,
                "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« (*.txt)"
            )
            
            if not file_path:
                return
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            success = self.whisper_transcriber.save_transcription_to_file(
                segments,
                file_path,
                include_timestamps=True
            )
            
            if success:
                QMessageBox.information(self, "å®Œäº†", f"æ–‡å­—èµ·ã“ã—ã‚’ä¿å­˜ã—ã¾ã—ãŸ:\n{file_path}")
            else:
                QMessageBox.critical(self, "ã‚¨ãƒ©ãƒ¼", "ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
        except Exception as e:
            print(f"âŒ æ–‡å­—èµ·ã“ã—ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            QMessageBox.critical(self, "ã‚¨ãƒ©ãƒ¼", f"ä¿å­˜ã‚¨ãƒ©ãƒ¼:\n{str(e)}")
    
    def on_wav_playback_started(self, start_position: float):
        """WAVå†ç”Ÿé–‹å§‹"""
        try:
            print(f"â–¶ï¸ WAVå†ç”Ÿé–‹å§‹: {start_position:.2f}ç§’ã‹ã‚‰")
            
            # WAVãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§å†ç”Ÿ
            self.wav_player.play(start_position)
            
            # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é€£å‹•é–‹å§‹
            wav_control = self.tabbed_audio_control.get_wav_playback_control()
            if wav_control.is_lipsync_enabled() and self._wav_lipsync_data:
                self._start_wav_lipsync(start_position)
            
        except Exception as e:
            print(f"âŒ WAVå†ç”Ÿé–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
    
    def on_wav_playback_paused(self):
        """WAVå†ç”Ÿä¸€æ™‚åœæ­¢"""
        try:
            print("â¸ï¸ WAVä¸€æ™‚åœæ­¢")
            self.wav_player.pause()
            self._stop_wav_lipsync()
            
        except Exception as e:
            print(f"âŒ WAVä¸€æ™‚åœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
    
    def on_wav_playback_stopped(self):
        """WAVå†ç”Ÿåœæ­¢"""
        try:
            print("â¹ï¸ WAVåœæ­¢")
            self.wav_player.stop()
            self._stop_wav_lipsync()
            
        except Exception as e:
            print(f"âŒ WAVåœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
    
    def on_wav_position_changed(self, position: float):
        """WAVå†ç”Ÿä½ç½®å¤‰æ›´ï¼ˆã‚·ãƒ¼ã‚¯ï¼‰"""
        try:
            print(f"ğŸ¯ WAVã‚·ãƒ¼ã‚¯: {position:.2f}ç§’")
            self.wav_player.seek(position)
            
            # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å†é–‹
            wav_control = self.tabbed_audio_control.get_wav_playback_control()
            if wav_control.is_lipsync_enabled() and self._wav_lipsync_data:
                self._start_wav_lipsync(position)
            
        except Exception as e:
            print(f"âŒ WAVã‚·ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
    
    def on_wav_volume_changed(self, volume: float):
        """WAVéŸ³é‡å¤‰æ›´"""
        try:
            self.wav_player.set_volume(volume)
            
        except Exception as e:
            print(f"âŒ WAVéŸ³é‡å¤‰æ›´ã‚¨ãƒ©ãƒ¼: {e}")
    
    def on_wav_player_position_update(self, position: float):
        """WAVãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‹ã‚‰ã®ä½ç½®æ›´æ–°"""
        try:
            # UIå´ã«é€šçŸ¥
            wav_control = self.tabbed_audio_control.get_wav_playback_control()
            wav_control.update_position(position)
            
        except Exception as e:
            print(f"âŒ WAVä½ç½®æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    def on_wav_player_finished(self):
        """WAVå†ç”Ÿå®Œäº†"""
        try:
            print("âœ… WAVå†ç”Ÿå®Œäº†")
            
            # UIå´ã«é€šçŸ¥
            wav_control = self.tabbed_audio_control.get_wav_playback_control()
            wav_control.on_playback_finished()
            
            # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯åœæ­¢
            self._stop_wav_lipsync()
            
        except Exception as e:
            print(f"âŒ WAVå®Œäº†å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _start_wav_lipsync(self, start_position: float):
        """WAVãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é–‹å§‹"""
        try:
            if not self._wav_lipsync_data:
                print("âš ï¸ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return
            
            if not (hasattr(self.character_display, 'live2d_webview') and 
                    self.character_display.live2d_webview.is_model_loaded):
                print("âš ï¸ Live2Dãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                return
            
            # é–‹å§‹ä½ç½®ã‹ã‚‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            filtered_frames = [
                frame for frame in self._wav_lipsync_data.vowel_frames
                if frame.timestamp >= start_position
            ]
            
            if not filtered_frames:
                print("âš ï¸ è©²å½“ã™ã‚‹ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ•ãƒ¬ãƒ¼ãƒ ãŒã‚ã‚Šã¾ã›ã‚“")
                return
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’èª¿æ•´ï¼ˆé–‹å§‹ä½ç½®ã‚’0ã¨ã™ã‚‹ï¼‰
            adjusted_frames = []
            for frame in filtered_frames:
                from core.lip_sync_engine import VowelFrame
                adjusted_frame = VowelFrame(
                    timestamp=frame.timestamp - start_position,
                    vowel=frame.vowel,
                    intensity=frame.intensity,
                    duration=frame.duration,
                    is_ending=frame.is_ending
                )
                adjusted_frames.append(adjusted_frame)
            
            # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ãƒ¼ã‚¿æº–å‚™
            simple_data = {
                'text': self._wav_lipsync_data.text,
                'duration': self._wav_lipsync_data.total_duration - start_position,
                'frames': [
                    {
                        'time': frame.timestamp,
                        'vowel': frame.vowel,
                        'intensity': frame.intensity,
                        'duration': frame.duration
                    }
                    for frame in adjusted_frames
                ]
            }
            
            # Live2Dã«é€ä¿¡
            self.character_display.mark_lipsync_in_progress(True)
            
            webview = self.character_display.live2d_webview
            import json
            data_json = json.dumps(simple_data, ensure_ascii=False)
            
            script = f"""
            (function() {{
                try {{
                    const lipSyncData = {data_json};
                    console.log('ğŸ­ WAVãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é–‹å§‹:', lipSyncData.frames.length, 'ãƒ•ãƒ¬ãƒ¼ãƒ ');
                    
                    if (typeof window.startSimpleLipSync === 'function') {{
                        return window.startSimpleLipSync(lipSyncData);
                    }} else {{
                        console.error('âŒ startSimpleLipSyncé–¢æ•°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
                        return false;
                    }}
                }} catch (error) {{
                    console.error('âŒ WAVãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚¨ãƒ©ãƒ¼:', error);
                    return false;
                }}
            }})()
            """
            
            webview.page().runJavaScript(script)
            
            # è¨­å®šã‚’å¼·åˆ¶åŒæœŸ
            QTimer.singleShot(10, self.character_display.sync_current_live2d_settings_to_webview)
            
            print(f"ğŸ­ WAVãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é€ä¿¡å®Œäº†: {len(adjusted_frames)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
            
        except Exception as e:
            print(f"âŒ WAVãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            self.character_display.mark_lipsync_in_progress(False)
    
    def _stop_wav_lipsync(self):
        """WAVãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯åœæ­¢"""
        try:
            if not (hasattr(self.character_display, 'live2d_webview') and 
                    self.character_display.live2d_webview.is_model_loaded):
                return
            
            webview = self.character_display.live2d_webview
            
            script = """
            (function() {
                try {
                    if (typeof window.stopSimpleLipSync === 'function') {
                        window.stopSimpleLipSync();
                        return true;
                    }
                    return false;
                } catch (error) {
                    console.error('âŒ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯åœæ­¢ã‚¨ãƒ©ãƒ¼:', error);
                    return false;
                }
            })()
            """
            
            webview.page().runJavaScript(script)
            
            self.character_display.mark_lipsync_in_progress(False)
            
            print("â¹ï¸ WAVãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯åœæ­¢")
            
        except Exception as e:
            print(f"âŒ WAVãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯åœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")