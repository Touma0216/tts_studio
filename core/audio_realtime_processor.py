import time
import numpy as np
from typing import List, Dict, Optional, Callable, Any, Tuple
from threading import Thread, Event, Lock
from queue import Queue, Empty
from dataclasses import dataclass
import traceback

try:
    from scipy import signal
    from scipy.fft import fft, fftfreq
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False
    print("âš ï¸ scipy ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚éŸ³å£°è§£ææ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã¾ã™ã€‚")

@dataclass
class AudioFrame:
    """éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿"""
    timestamp: float    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆç§’ï¼‰
    audio_data: np.ndarray  # éŸ³å£°ãƒ‡ãƒ¼ã‚¿
    sample_rate: int    # ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ
    frame_size: int     # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚º
    rms_level: float    # RMSãƒ¬ãƒ™ãƒ«
    dominant_freq: float # ä¸»è¦å‘¨æ³¢æ•°

@dataclass
class VowelDetectionResult:
    """æ¯éŸ³æ¤œå‡ºçµæœ"""
    timestamp: float    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    vowel: str         # æ¤œå‡ºã•ã‚ŒãŸæ¯éŸ³
    confidence: float  # ä¿¡é ¼åº¦ (0.0-1.0)
    formant_f1: float  # ç¬¬1ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆ
    formant_f2: float  # ç¬¬2ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆ
    intensity: float   # å¼·åº¦

class AudioRealtimeProcessor:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³
    
    éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è§£æã—ã€
    æ¯éŸ³æ¤œå‡ºã¨ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹
    """
    
    def __init__(self, sample_rate: int = 22050, frame_size: int = 1024):
        self.sample_rate = sample_rate
        self.frame_size = frame_size
        self.hop_size = frame_size // 2
        
        # å‡¦ç†çŠ¶æ…‹
        self.is_processing = False
        self.processing_thread = None
        self.stop_event = Event()
        
        # ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¥ãƒ¼
        self.audio_queue = Queue(maxsize=100)
        self.result_queue = Queue(maxsize=50)
        
        # åŒæœŸç”¨ãƒ­ãƒƒã‚¯
        self.process_lock = Lock()
        
        # æ¯éŸ³æ¤œå‡ºè¨­å®š
        self.vowel_detection_settings = {
            'enabled': True,
            'confidence_threshold': 0.6,
            'smoothing_window': 3,
            'formant_analysis': SCIPY_AVAILABLE
        }
        
        # ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆå‘¨æ³¢æ•°ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ—¥æœ¬èªæ¯éŸ³ï¼‰
        self.vowel_formant_table = {
            'a': {'f1_range': (600, 900), 'f2_range': (1000, 1400)},   # ã‚
            'i': {'f1_range': (200, 400), 'f2_range': (2000, 2800)},   # ã„  
            'u': {'f1_range': (200, 400), 'f2_range': (600, 1200)},    # ã†
            'e': {'f1_range': (400, 600), 'f2_range': (1400, 2000)},   # ãˆ
            'o': {'f1_range': (400, 600), 'f2_range': (600, 1200)}     # ãŠ
        }
        
        # éŸ³å£°è§£æãƒãƒƒãƒ•ã‚¡
        self.analysis_buffer = np.array([])
        self.buffer_max_length = sample_rate * 2  # 2ç§’åˆ†ã®ãƒãƒƒãƒ•ã‚¡
        
        # çµæœã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        self.vowel_callback = None
        self.frame_callback = None
        
        print(f"âœ… AudioRealtimeProcessoråˆæœŸåŒ–å®Œäº†")
        print(f"   ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {sample_rate}Hz, ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚º: {frame_size}")
        print(f"   scipyåˆ©ç”¨å¯èƒ½: {'Yes' if SCIPY_AVAILABLE else 'No'}")
    
    def set_vowel_callback(self, callback: Callable[[VowelDetectionResult], None]):
        """æ¯éŸ³æ¤œå‡ºçµæœã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š"""
        self.vowel_callback = callback
    
    def set_frame_callback(self, callback: Callable[[AudioFrame], None]):
        """éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š"""
        self.frame_callback = callback
    
    def start_processing(self):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†é–‹å§‹"""
        if self.is_processing:
            print("âš ï¸ æ—¢ã«å‡¦ç†ä¸­ã§ã™")
            return
        
        try:
            self.is_processing = True
            self.stop_event.clear()
            
            # å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
            self.processing_thread = Thread(
                target=self._processing_loop,
                name="AudioRealtimeProcessor",
                daemon=True
            )
            self.processing_thread.start()
            
            print("ğŸµ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
            
        except Exception as e:
            print(f"âŒ å‡¦ç†é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
            self.is_processing = False
    
    def stop_processing(self):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†åœæ­¢"""
        if not self.is_processing:
            return
        
        print("â¹ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†ã‚’åœæ­¢ä¸­...")
        
        self.stop_event.set()
        self.is_processing = False
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†ã‚’å¾…æ©Ÿ
        if self.processing_thread and self.processing_thread.is_alive():
            self.processing_thread.join(timeout=2.0)
        
        # ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢
        self._clear_queues()
        
        print("âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†ã‚’åœæ­¢ã—ã¾ã—ãŸ")
    
    def add_audio_data(self, audio_data: np.ndarray, timestamp: float = None) -> bool:
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
        
        Args:
            audio_data: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ï¼ˆnumpyé…åˆ—ï¼‰
            timestamp: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆNoneã®å ´åˆã¯ç¾åœ¨æ™‚åˆ»ï¼‰
            
        Returns:
            bool: è¿½åŠ æˆåŠŸæ™‚True
        """
        try:
            if timestamp is None:
                timestamp = time.time()
            
            # ãƒ‡ãƒ¼ã‚¿å½¢å¼ãƒã‚§ãƒƒã‚¯
            if not isinstance(audio_data, np.ndarray):
                audio_data = np.array(audio_data, dtype=np.float32)
            
            # æ­£è¦åŒ–
            if audio_data.dtype != np.float32:
                if audio_data.dtype == np.int16:
                    audio_data = audio_data.astype(np.float32) / 32768.0
                elif audio_data.dtype == np.int32:
                    audio_data = audio_data.astype(np.float32) / 2147483648.0
                else:
                    audio_data = audio_data.astype(np.float32)
            
            # ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
            frame_data = {
                'audio_data': audio_data,
                'timestamp': timestamp,
                'sample_rate': self.sample_rate
            }
            
            if not self.audio_queue.full():
                self.audio_queue.put(frame_data, timeout=0.1)
                return True
            else:
                print("âš ï¸ éŸ³å£°ã‚­ãƒ¥ãƒ¼ãŒæº€æ¯ã§ã™")
                return False
                
        except Exception as e:
            print(f"âŒ éŸ³å£°ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def get_latest_vowel_result(self) -> Optional[VowelDetectionResult]:
        """æœ€æ–°ã®æ¯éŸ³æ¤œå‡ºçµæœã‚’å–å¾—"""
        try:
            return self.result_queue.get(timeout=0.01)
        except Empty:
            return None
    
    def _processing_loop(self):
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ«ãƒ¼ãƒ—"""
        print("ğŸ”„ éŸ³å£°å‡¦ç†ãƒ«ãƒ¼ãƒ—é–‹å§‹")
        
        try:
            while not self.stop_event.is_set():
                try:
                    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    frame_data = self.audio_queue.get(timeout=0.1)
                    
                    # ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
                    self._process_audio_frame(frame_data)
                    
                except Empty:
                    continue
                except Exception as e:
                    print(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    time.sleep(0.01)
                    
        except Exception as e:
            print(f"âŒ å‡¦ç†ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
            print(traceback.format_exc())
        finally:
            print("ğŸ”„ éŸ³å£°å‡¦ç†ãƒ«ãƒ¼ãƒ—çµ‚äº†")
    
    def _process_audio_frame(self, frame_data: Dict[str, Any]):
        """éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†"""
        try:
            audio_data = frame_data['audio_data']
            timestamp = frame_data['timestamp']
            sample_rate = frame_data.get('sample_rate', self.sample_rate)
            
            # ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
            self._update_analysis_buffer(audio_data)
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†æ
            audio_frame = self._analyze_audio_frame(audio_data, timestamp, sample_rate)
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
            if self.frame_callback:
                self.frame_callback(audio_frame)
            
            # æ¯éŸ³æ¤œå‡ºï¼ˆæœ‰åŠ¹ãªå ´åˆã®ã¿ï¼‰
            if self.vowel_detection_settings['enabled'] and len(self.analysis_buffer) >= self.frame_size:
                vowel_result = self._detect_vowel(audio_frame)
                if vowel_result:
                    # çµæœã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
                    if not self.result_queue.full():
                        self.result_queue.put(vowel_result)
                    
                    # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
                    if self.vowel_callback:
                        self.vowel_callback(vowel_result)
            
        except Exception as e:
            print(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _update_analysis_buffer(self, audio_data: np.ndarray):
        """è§£æç”¨ãƒãƒƒãƒ•ã‚¡ã‚’æ›´æ–°"""
        with self.process_lock:
            # ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
            self.analysis_buffer = np.concatenate([self.analysis_buffer, audio_data])
            
            # ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºåˆ¶é™
            if len(self.analysis_buffer) > self.buffer_max_length:
                excess = len(self.analysis_buffer) - self.buffer_max_length
                self.analysis_buffer = self.analysis_buffer[excess:]
    
    def _analyze_audio_frame(self, audio_data: np.ndarray, timestamp: float, sample_rate: int) -> AudioFrame:
        """éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã®åŸºæœ¬åˆ†æ"""
        try:
            # RMSãƒ¬ãƒ™ãƒ«è¨ˆç®—
            rms_level = np.sqrt(np.mean(audio_data ** 2))
            
            # ä¸»è¦å‘¨æ³¢æ•°è¨ˆç®—ï¼ˆSCIPYä½¿ç”¨å¯èƒ½æ™‚ï¼‰
            dominant_freq = 0.0
            if SCIPY_AVAILABLE and len(audio_data) > 0:
                dominant_freq = self._calculate_dominant_frequency(audio_data, sample_rate)
            
            audio_frame = AudioFrame(
                timestamp=timestamp,
                audio_data=audio_data.copy(),
                sample_rate=sample_rate,
                frame_size=len(audio_data),
                rms_level=rms_level,
                dominant_freq=dominant_freq
            )
            
            return audio_frame
            
        except Exception as e:
            print(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return AudioFrame(
                timestamp=timestamp,
                audio_data=audio_data,
                sample_rate=sample_rate,
                frame_size=len(audio_data),
                rms_level=0.0,
                dominant_freq=0.0
            )
    
    def _calculate_dominant_frequency(self, audio_data: np.ndarray, sample_rate: int) -> float:
        """ä¸»è¦å‘¨æ³¢æ•°ã‚’è¨ˆç®—"""
        try:
            if len(audio_data) < 64:  # æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°ãƒã‚§ãƒƒã‚¯
                return 0.0
            
            # FFTè¨ˆç®—
            fft_data = fft(audio_data)
            freqs = fftfreq(len(audio_data), 1.0 / sample_rate)
            
            # ãƒ‘ãƒ¯ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ«
            power_spectrum = np.abs(fft_data)
            
            # æ­£ã®å‘¨æ³¢æ•°ã®ã¿
            positive_freqs = freqs[:len(freqs)//2]
            positive_power = power_spectrum[:len(power_spectrum)//2]
            
            # ä¸»è¦å‘¨æ³¢æ•°æ¤œå‡º
            if len(positive_power) > 0:
                max_idx = np.argmax(positive_power)
                dominant_freq = positive_freqs[max_idx]
                return abs(dominant_freq)
            
            return 0.0
            
        except Exception as e:
            print(f"âš ï¸ å‘¨æ³¢æ•°è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def _detect_vowel(self, audio_frame: AudioFrame) -> Optional[VowelDetectionResult]:
        """æ¯éŸ³æ¤œå‡º"""
        try:
            if not SCIPY_AVAILABLE:
                return self._simple_vowel_detection(audio_frame)
            
            # ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆè§£æã«ã‚ˆã‚‹æ¯éŸ³æ¤œå‡º
            formants = self._extract_formants(audio_frame.audio_data, audio_frame.sample_rate)
            
            if not formants or len(formants) < 2:
                return self._simple_vowel_detection(audio_frame)
            
            f1, f2 = formants[0], formants[1]
            
            # ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆã‹ã‚‰æ¯éŸ³ã‚’æ¨å®š
            vowel, confidence = self._classify_vowel_by_formants(f1, f2)
            
            # ä¿¡é ¼åº¦ãƒã‚§ãƒƒã‚¯
            if confidence < self.vowel_detection_settings['confidence_threshold']:
                return None
            
            # å¼·åº¦è¨ˆç®—
            intensity = min(1.0, audio_frame.rms_level * 5.0)
            
            vowel_result = VowelDetectionResult(
                timestamp=audio_frame.timestamp,
                vowel=vowel,
                confidence=confidence,
                formant_f1=f1,
                formant_f2=f2,
                intensity=intensity
            )
            
            return vowel_result
            
        except Exception as e:
            print(f"âš ï¸ æ¯éŸ³æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return self._simple_vowel_detection(audio_frame)
    
    def _extract_formants(self, audio_data: np.ndarray, sample_rate: int) -> List[float]:
        """ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆæŠ½å‡º"""
        try:
            if len(audio_data) < self.frame_size:
                return []
            
            # çª“é–¢æ•°é©ç”¨
            windowed = audio_data * np.hanning(len(audio_data))
            
            # FFT
            fft_data = fft(windowed)
            freqs = fftfreq(len(windowed), 1.0 / sample_rate)
            power_spectrum = np.abs(fft_data)
            
            # æ­£ã®å‘¨æ³¢æ•°ã®ã¿
            positive_freqs = freqs[:len(freqs)//2]
            positive_power = power_spectrum[:len(power_spectrum)//2]
            
            # ãƒ”ãƒ¼ã‚¯æ¤œå‡ºï¼ˆãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆå€™è£œï¼‰
            peaks = []
            
            # 200-3000Hzç¯„å›²ã§ãƒ”ãƒ¼ã‚¯æ¤œå‡º
            freq_min, freq_max = 200, 3000
            start_idx = np.argmin(np.abs(positive_freqs - freq_min))
            end_idx = np.argmin(np.abs(positive_freqs - freq_max))
            
            if start_idx >= end_idx:
                return []
            
            # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ”ãƒ¼ã‚¯æ¤œå‡º
            search_range = positive_power[start_idx:end_idx]
            search_freqs = positive_freqs[start_idx:end_idx]
            
            # ãƒ­ãƒ¼ã‚«ãƒ«ãƒã‚­ã‚·ãƒæ¤œå‡º
            for i in range(1, len(search_range) - 1):
                if (search_range[i] > search_range[i-1] and 
                    search_range[i] > search_range[i+1] and
                    search_range[i] > np.max(search_range) * 0.1):  # æœ€å¤§å€¤ã®10%ä»¥ä¸Š
                    
                    peaks.append((search_freqs[i], search_range[i]))
            
            # ãƒ‘ãƒ¯ãƒ¼ã§ã‚½ãƒ¼ãƒˆ
            peaks.sort(key=lambda x: x[1], reverse=True)
            
            # ä¸Šä½ã®ãƒ”ãƒ¼ã‚¯ã‚’ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆã¨ã—ã¦è¿”ã™
            formants = [peak[0] for peak in peaks[:4]]  # æœ€å¤§4å€‹ã®ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆ
            
            return sorted(formants)  # å‘¨æ³¢æ•°é †ã«ã‚½ãƒ¼ãƒˆ
            
        except Exception as e:
            print(f"âš ï¸ ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _classify_vowel_by_formants(self, f1: float, f2: float) -> Tuple[str, float]:
        """ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆå€¤ã‹ã‚‰æ¯éŸ³ã‚’åˆ†é¡"""
        try:
            best_vowel = 'a'
            best_score = 0.0
            
            for vowel, formant_info in self.vowel_formant_table.items():
                f1_range = formant_info['f1_range']
                f2_range = formant_info['f2_range']
                
                # å„ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆã®é©åˆåº¦è¨ˆç®—
                f1_score = self._calculate_range_score(f1, f1_range)
                f2_score = self._calculate_range_score(f2, f2_range)
                
                # ç·åˆã‚¹ã‚³ã‚¢
                total_score = (f1_score + f2_score) / 2
                
                if total_score > best_score:
                    best_score = total_score
                    best_vowel = vowel
            
            return best_vowel, best_score
            
        except Exception as e:
            print(f"âš ï¸ æ¯éŸ³åˆ†é¡ã‚¨ãƒ©ãƒ¼: {e}")
            return 'a', 0.5
    
    def _calculate_range_score(self, value: float, range_tuple: Tuple[float, float]) -> float:
        """å€¤ãŒç¯„å›²ã«ã©ã‚Œã ã‘é©åˆã™ã‚‹ã‹ã‚¹ã‚³ã‚¢åŒ–"""
        min_val, max_val = range_tuple
        
        if min_val <= value <= max_val:
            # ç¯„å›²å†…ã®å ´åˆã€ä¸­å¤®ã«è¿‘ã„ã»ã©é«˜ã‚¹ã‚³ã‚¢
            center = (min_val + max_val) / 2
            distance = abs(value - center)
            max_distance = (max_val - min_val) / 2
            return 1.0 - (distance / max_distance)
        else:
            # ç¯„å›²å¤–ã®å ´åˆã€è·é›¢ã«å¿œã˜ã¦æ¸›ç‚¹
            if value < min_val:
                distance = min_val - value
            else:
                distance = value - max_val
            
            # ç¯„å›²å¹…ã®2å€ã¾ã§è¨±å®¹ï¼ˆãã‚Œä»¥ä¸Šã¯0ç‚¹ï¼‰
            tolerance = (max_val - min_val) * 2
            return max(0.0, 1.0 - (distance / tolerance))
    
    def _simple_vowel_detection(self, audio_frame: AudioFrame) -> Optional[VowelDetectionResult]:
        """ã‚·ãƒ³ãƒ—ãƒ«æ¯éŸ³æ¤œå‡ºï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        try:
            # RMSãƒ¬ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“æ¤œå‡º
            rms_level = audio_frame.rms_level
            
            # éŸ³é‡ãŒä½ã™ãã‚‹å ´åˆã¯ç„¡éŸ³
            if rms_level < 0.01:
                return VowelDetectionResult(
                    timestamp=audio_frame.timestamp,
                    vowel='sil',
                    confidence=0.8,
                    formant_f1=0.0,
                    formant_f2=0.0,
                    intensity=0.0
                )
            
            # ä¸»è¦å‘¨æ³¢æ•°ãƒ™ãƒ¼ã‚¹ã®æ¨å®š
            dominant_freq = audio_frame.dominant_freq
            
            # ç°¡æ˜“çš„ãªæ¯éŸ³æ¨å®šï¼ˆå‘¨æ³¢æ•°ãƒ™ãƒ¼ã‚¹ï¼‰
            if dominant_freq < 500:
                vowel = 'u'  # ä½ã„å‘¨æ³¢æ•°ï¼šã†
            elif dominant_freq < 1000:
                vowel = 'o'  # ä¸­ä½åŸŸï¼šãŠ
            elif dominant_freq < 1500:
                vowel = 'a'  # ä¸­åŸŸï¼šã‚
            elif dominant_freq < 2000:
                vowel = 'e'  # ä¸­é«˜åŸŸï¼šãˆ
            else:
                vowel = 'i'  # é«˜ã„å‘¨æ³¢æ•°ï¼šã„
            
            intensity = min(1.0, rms_level * 3.0)
            
            return VowelDetectionResult(
                timestamp=audio_frame.timestamp,
                vowel=vowel,
                confidence=0.6,
                formant_f1=dominant_freq * 0.3,
                formant_f2=dominant_freq,
                intensity=intensity
            )
            
        except Exception as e:
            print(f"âš ï¸ ã‚·ãƒ³ãƒ—ãƒ«æ¯éŸ³æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _clear_queues(self):
        """ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢"""
        try:
            while not self.audio_queue.empty():
                self.audio_queue.get_nowait()
        except Empty:
            pass
        
        try:
            while not self.result_queue.empty():
                self.result_queue.get_nowait()
        except Empty:
            pass
    
    def update_settings(self, settings: Dict[str, Any]):
        """å‡¦ç†è¨­å®šã‚’æ›´æ–°"""
        try:
            if 'vowel_detection' in settings:
                vowel_settings = settings['vowel_detection']
                self.vowel_detection_settings.update(vowel_settings)
                print(f"ğŸ”§ æ¯éŸ³æ¤œå‡ºè¨­å®šæ›´æ–°: {vowel_settings}")
            
            if 'frame_size' in settings:
                new_frame_size = settings['frame_size']
                if new_frame_size != self.frame_size:
                    self.frame_size = new_frame_size
                    self.hop_size = new_frame_size // 2
                    print(f"ğŸ”§ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚ºæ›´æ–°: {new_frame_size}")
            
        except Exception as e:
            print(f"âŒ è¨­å®šæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """å‡¦ç†çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        return {
            'is_processing': self.is_processing,
            'audio_queue_size': self.audio_queue.qsize(),
            'result_queue_size': self.result_queue.qsize(),
            'buffer_length': len(self.analysis_buffer),
            'sample_rate': self.sample_rate,
            'frame_size': self.frame_size,
            'scipy_available': SCIPY_AVAILABLE,
            'vowel_detection_enabled': self.vowel_detection_settings['enabled']
        }
    
    def __del__(self):
        """ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿"""
        self.stop_processing()